---
title: "ExAC Data Tidying"
output:
  html_notebook: default
  html_document: default
---

This data is from the exon skipping MPRA. Briefly, we design an intron-exon-intron library and place it in between a split GFP reporter. If the exon is skipped, the GFP will be reconstitued and will glow. If the exon is included, the GFP will remain split and will not glow. There is also a downstream constitutive RFP reporter gene. The library of cells was sorted based on both RFP and GFP into three bins (described below).

This notebook tidies up and processes the aggregated alignment data for all replicates and bins. This data is for the ExAC library. The design is based off the previous "splicemod" mutation library. We took the top 2000 most included exons and designed all SNP variants as catalogued in the ExAC database.

```{r setup, echo=F, message=F}
library(dplyr)
library(tidyr)
library(ggplot2)
library(cowplot)
options(stringsAsFactors = F)

knitr::opts_chunk$set(warning=FALSE, message=F)

data <- read.csv('../produced_data/all_alignments.csv')
```

All of read alignment data for each sample is contained in `all_alignments.csv`. The rows correspond to different sequences, referenced by Ensembl IDs and other information in the header. Each column corresponds to a different sample, and the number is the count of that sequence in that sample. The sample names follow the format 'DP1S1'. There are three sample types, double positive (DP), single positive (SP), and intermediate (INT). The number following the sample type corresponds to the replicate number (1 or 2). DP refers to both a GFP and RFP signal, indicating the exon was skipped. SP refers to single positive, indicating there was only RFP and no GFP and that the exon was included. Intermediate refers to a GFP/RFP ratio that falls in between double and single positive. There are three sort types, sort 1 (S1), sort 2 (S2) and pre-sort (PS). Sort 1 refers to the initial sorting of the library into three bins. This initial sort is not very precise, so a second sort was performed on the entire population from the first sort. The library was also sequenced prior to sorting (pre-sort).

We only care about the second sort, so filter out samples that end with 'S1' (sort 1)

```{r trim_columns}
data <- select(data, -ends_with('S1'))
```

Next, let's normalize the read counts. To normalize for sequencing depeth, we divide each count by the number of million reads per sample. To account for the different proportion of cells in each bin, we multiply each by its proportion relative to the presort (this is determined from the sorting, use hard-coded values).

```{r normalize}
data <- data %>%
    select(-id) %>% 
    mutate_each(funs(norm = . / (sum(.) / 1000000))) %>% 
    select(ends_with('norm')) %>% # get rid of original un-normalized columns
    bind_cols(select(data, id), .)

# proportion of cells in each bin (relative to pre-sort)
# DP1S2, DP2S2, INT1S2, INT2S2, PS_R1, PS_R2, SP1S2, SP2S2
bin_prop <- c( 0.092, 0.091,  0.127, 0.122, 1, 1, 0.596, 0.603)

# rename for convenience
colnames(data) <- c('header', 'DP_R1', 'DP_R2', 'INT_R1', 'INT_R2', 'PS_R1', 'PS_R2', 'SP_R1', 'SP_R2')

# multiply each bin count by bin proportion
data <- cbind(header = data$header, data.frame(mapply(`*`, select(data, DP_R1:SP_R2), bin_prop, SIMPLIFY = FALSE)))
```

Now time to parse the id into separate columns.
```{r parse_header}
# small substitutions so separate will work easier
data$header <- gsub('strand= ', 'strand=', data$header)
data$header <- gsub('>', '', data$header)
data <- data %>%
    separate(header, into = c('id', 'chr', 'strand', 'length', 'category'), sep = ' ') %>% 
    separate(chr, c('chr', 'region'), sep = ':') %>%
    separate(region, c('start', 'end'), sep = '-', fill = 'right') %>%
    separate(id, c('ensembl_id', 'sub_id'), sep = '_', remove = F)

# get rid of leftover field identifiers    
data$strand <- gsub('strand=', '', data$strand)
data$length <- gsub('len=', '', data$length)

# convert to numeric
data$chr <- as.numeric(gsub('chr', '', data$chr))
data$start <- as.numeric(data$start)
data$end <- as.numeric(data$end)

# finally, separate length into intron-exon-intron lengths
data <- data %>%
    extract(length, c("intron1_len","exon_len","intron2_len"), "([[:alnum:]]+).([[:alnum:]]+).([[:alnum:]]+)")

data$intron1_len <- as.numeric(data$intron1_len)
data$intron2_len <- as.numeric(data$intron2_len)
data$exon_len <- as.numeric(data$exon_len)

# update the category to either control, natural, or mutant
data <- data %>% 
    # ifelse() structure: ifelse(condition, action if true, action if false)
    mutate(category = ifelse(endsWith(id, '000'), 'natural', 'mutant')) %>% 
    mutate(category = ifelse(endsWith(id, 'BRK'), 'control', category))
```

Next, let's calculate a splicing index for each construct, a measure of how included an exon is. We will use a simple weighted average, where the double positive has weight 0, intermediate weight 0.85, and single positive weight 1.

```{r splicing_index}
data <- data %>%
    mutate(index_R1 = (DP_R1*0 + INT_R1*0.85 + SP_R1*1) / (DP_R1 + INT_R1 + SP_R1),
           index_R2 = (DP_R2*0 + INT_R2*0.85 + SP_R2*1) / (DP_R2 + INT_R2 + SP_R2))

# replace NaN with NA
data[data == 'NaN'] <- NA
```

Let's take a quick peek at the data
```{r index_graph}
ggplot(data, aes(index_R1, index_R2)) + geom_point(alpha = 0.25) +
    labs(x = 'replicate 1 splicing index', y = 'replicate 2 splicing index',
         title = 'Comparison of splicing index across replicates')
```

